#!/bin/bash -l
#SBATCH --nodes=1 --ntasks-per-node=40
cd $SLURM_SUBMIT_DIR

date

# change working directory to folder with the filtered paired-end reads
cd /home/colleen_ahern/g3dir/filtg3

mkdir home/colleen_ahern/g3dir/filtg3/transcriptome/Filtered_Raw_Data/fastqfilt/fastqfilt_sep
cd home/colleen_ahern/g3dir/filtg3/transcriptome/Filtered_Raw_Data/fastqfilt

# STEP 1: use BBmap to separate the fastq files into read1 and read2:
for file in g3dir/filtg3/transcriptome/Filtered_Raw_Data/fastqfilt/*fastq.gz; do b=$(echo "$file" | awk '{print substr($0,0,55)}')fastqfilt_sep/; c=$(echo "$file" | awk '{print substr($0,56,32)}'); d='_read1.fq.gz'; e='_read2.fq.gz'; bbmap/reformat.sh in=$file overrideinterleaved=t append=t out1=$b$c$d out2=$b$c$e; done
cd /home/colleen_ahern/g3dir/filtg3

# STEP 2: build genome index for HISAT2
# conda activate hisat2
# Build genome index from assembled scaffold file
hisat2-build Neocon1/Neocon1_AssemblyScaffolds.fasta Neocon1/genindx/genome_index

# STEP 3: map reads to the genome using HISAT2
mkdir HISAT2
for file in g3dir/filtg3/transcriptome/Filtered_Raw_Data/fastqfilt/fastqfilt_sep/*read1.fq.gz; do a=$(echo "$file" | awk '{print substr($0,0,106)}')2.fq.gz; b='g3dir/filtg3/HISAT2dan/'; c=$(echo "$file" | awk '{print substr($0,70,32)}')_hits.sam; hisat2 -p 12 -k 1 -x g3dir/filtg3/genome/Neocon1/genindx/genome_index -1 $file -2 $a > $b$c; done

# STEP 4: Convert HISAT2 .sam files to .bam files
cd g3dir/filtg3/HISAT2dan
conda activate samtools
for file in *.sam; do samtools sort -@ 8 -o ${file%.sam}.bam $file; done

# STEP 5: run featureCounts (to estimate transcript abundance)
cd /home/colleen_ahern/g3dir/filtg3
mkdir filtfeatcountdan
featureCounts -a genome/Neocon1/Neocon1_GeneCatalog_20220615.gff3 -s 2 -p --primary -T 12 -t "gene" -g "ID" -o filtfeatcountdan/filtfeaturecountsdan.txt HISAT2dan/*.bam

date
